{"cells":[{"cell_type":"markdown","metadata":{"id":"otbCBGrfTFy8"},"source":["Before you submit this notebook, make sure everything runs as expected in the local test cases.\n","Please, paste the solution to the designed cell and do not change anything else.\n","\n","Also, please, leave your first and last names below"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"1d0hWBxmTFzB","executionInfo":{"status":"ok","timestamp":1722350001674,"user_tz":-180,"elapsed":638,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"outputs":[],"source":["FirstName = \"\"\n","LastName = \"\""]},{"cell_type":"markdown","metadata":{"id":"n3XiO-O9TFzF"},"source":["---"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"Hf8sZKOlTFzF","executionInfo":{"status":"ok","timestamp":1722350002649,"user_tz":-180,"elapsed":7,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"outputs":[],"source":["import numpy as np\n","from sklearn.base import BaseEstimator\n","from sklearn.preprocessing import OneHotEncoder"]},{"cell_type":"code","execution_count":83,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"40b231b30fc9f58984904a569710f504","grade":false,"grade_id":"cell-ac8fc52d8a39ccb4","locked":false,"schema_version":3,"solution":true,"task":false},"id":"VyiD0PKATFzG","executionInfo":{"status":"ok","timestamp":1722351685852,"user_tz":-180,"elapsed":342,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"outputs":[],"source":["def entropy(y):\n","    \"\"\"\n","    Computes entropy of the provided distribution. Use log(value + eps) for numerical stability\n","\n","    Parameters\n","    ----------\n","    y : np.array of type float with shape (n_objects, n_classes)\n","        One-hot representation of class labels for corresponding subset\n","\n","    Returns\n","    -------\n","    float\n","        Entropy of the provided subset\n","    \"\"\"\n","    EPS = 0.0005\n","\n","    # YOUR CODE HERE\n","    p = np.mean(y, axis=0)\n","    return -np.sum(p * np.log(p + EPS))\n","\n","\n","def gini(y):\n","    \"\"\"\n","    Computes the Gini impurity of the provided distribution\n","\n","    Parameters\n","    ----------\n","    y : np.array of type float with shape (n_objects, n_classes)\n","        One-hot representation of class labels for corresponding subset\n","\n","    Returns\n","    -------\n","    float\n","        Gini impurity of the provided subset\n","    \"\"\"\n","\n","    # YOUR CODE HERE\n","    p = np.mean(y, axis=0)\n","    return 1 - np.sum(p ** 2)\n","\n","\n","def variance(y):\n","    \"\"\"\n","    Computes the variance the provided target values subset\n","\n","    Parameters\n","    ----------\n","    y : np.array of type float with shape (n_objects, 1)\n","        Target values vector\n","\n","    Returns\n","    -------\n","    float\n","        Variance of the provided target vector\n","    \"\"\"\n","\n","    # YOUR CODE HERE\n","    return np.var(y)\n","\n","\n","def mad_median(y):\n","    \"\"\"\n","    Computes the mean absolute deviation from the median in the\n","    provided target values subset\n","\n","    Parameters\n","    ----------\n","    y : np.array of type float with shape (n_objects, 1)\n","        Target values vector\n","\n","    Returns\n","    -------\n","    float\n","        Mean absolute deviation from the median in the provided vector\n","    \"\"\"\n","\n","    # YOUR CODE HERE\n","    median = np.median(y)\n","    return np.mean(np.abs(y - median))\n","\n","\n","def one_hot_encode(n_classes, y):\n","    y_one_hot = np.zeros((len(y), n_classes), dtype=float)\n","    y_one_hot[np.arange(len(y)), y.astype(int)[:, 0]] = 1.\n","    return y_one_hot\n","\n","\n","def one_hot_decode(y_one_hot):\n","    return y_one_hot.argmax(axis=1)[:, None]\n","\n","\n","class Node:\n","    \"\"\"\n","    This class is provided \"as is\" and it is not mandatory to it use in your code.\n","    \"\"\"\n","\n","    def __init__(self, feature_index, threshold, proba=0):\n","        self.feature_index = feature_index\n","        self.value = threshold\n","        self.proba = proba\n","        self.left_child = None\n","        self.right_child = None\n","\n","\n","class DecisionTree(BaseEstimator):\n","    all_criterions = {\n","        'gini': (gini, True),  # (criterion, classification flag)\n","        'entropy': (entropy, True),\n","        'variance': (variance, False),\n","        'mad_median': (mad_median, False)\n","    }\n","\n","    def __init__(self, n_classes=None, max_depth=np.inf, min_samples_split=2,\n","                 criterion_name='gini', debug=False):\n","\n","        assert criterion_name in self.all_criterions.keys(), 'Criterion name must be on of the following: {}'.format(\n","            self.all_criterions.keys())\n","\n","        self.n_classes = n_classes\n","        self.max_depth = max_depth\n","        self.min_samples_split = min_samples_split\n","        self.criterion_name = criterion_name\n","\n","        self.depth = 0\n","        self.root = None  # Use the Node class to initialize it later\n","        self.debug = debug\n","\n","    def make_split(self, feature_index, threshold, X_subset, y_subset):\n","        \"\"\"\n","        Makes split of the provided data subset and target values using provided feature and threshold\n","\n","        Parameters\n","        ----------\n","        feature_index : int\n","            Index of feature to make split with\n","\n","        threshold : float\n","            Threshold value to perform split\n","\n","        X_subset : np.array of type float with shape (n_objects, n_features)\n","            Feature matrix representing the selected subset\n","\n","        y_subset : np.array of type float with shape (n_objects, n_classes) in classification\n","                   (n_objects, 1) in regression\n","            One-hot representation of class labels for corresponding subset\n","\n","        Returns\n","        -------\n","        (X_left, y_left) : tuple of np.arrays of same type as input X_subset and y_subset\n","            Part of the providev subset where selected feature x^j < threshold\n","        (X_right, y_right) : tuple of np.arrays of same type as input X_subset and y_subset\n","            Part of the providev subset where selected feature x^j >= threshold\n","        \"\"\"\n","\n","        # YOUR CODE HERE\n","        right_mask = X_subset[:, feature_index] >= threshold\n","        left_mask = ~right_mask\n","        return (X_subset[left_mask], y_subset[left_mask]), (X_subset[right_mask], y_subset[right_mask])\n","\n","    def make_split_only_y(self, feature_index, threshold, X_subset, y_subset):\n","        \"\"\"\n","        Split only target values into two subsets with specified feature and threshold\n","\n","        Parameters\n","        ----------\n","        feature_index : int\n","            Index of feature to make split with\n","\n","        threshold : float\n","            Threshold value to perform split\n","\n","        X_subset : np.array of type float with shape (n_objects, n_features)\n","            Feature matrix representing the selected subset\n","\n","        y_subset : np.array of type float with shape (n_objects, n_classes) in classification\n","                   (n_objects, 1) in regression\n","            One-hot representation of class labels for corresponding subset\n","\n","        Returns\n","        -------\n","        y_left : np.array of type float with shape (n_objects_left, n_classes) in classification\n","                   (n_objects, 1) in regression\n","            Part of the provided subset where selected feature x^j < threshold\n","\n","        y_right : np.array of type float with shape (n_objects_right, n_classes) in classification\n","                   (n_objects, 1) in regression\n","            Part of the provided subset where selected feature x^j >= threshold\n","        \"\"\"\n","\n","        # YOUR CODE HERE\n","        right_mask = X_subset[:, feature_index] >= threshold\n","        left_mask = ~right_mask\n","        return y_subset[left_mask], y_subset[right_mask]\n","\n","    def choose_best_split(self, X_subset, y_subset):\n","        \"\"\"\n","        Greedily select the best feature and best threshold w.r.t. selected criterion\n","\n","        Parameters\n","        ----------\n","        X_subset : np.array of type float with shape (n_objects, n_features)\n","            Feature matrix representing the selected subset\n","\n","        y_subset : np.array of type float with shape (n_objects, n_classes) in classification\n","                   (n_objects, 1) in regression\n","            One-hot representation of class labels or target values for corresponding subset\n","\n","        Returns\n","        -------\n","        feature_index : int\n","            Index of feature to make split with\n","\n","        threshold : float\n","            Threshold value to perform split\n","\n","        \"\"\"\n","        # YOUR CODE HERE\n","        best_feature = None\n","        best_threshold = None\n","        best_criterion_value = float('inf')\n","        n_features = X_subset.shape[1]\n","        for feature_index in range(n_features):\n","            thresholds = np.unique(X_subset[:, feature_index])\n","            for threshold in thresholds:\n","                y_left, y_right = self.make_split_only_y(feature_index, threshold, X_subset, y_subset)\n","                if len(y_left) < self.min_samples_split or len(y_right) < self.min_samples_split:\n","                    continue\n","                criterion_value = (len(y_left) * self.criterion(y_left) + len(y_right) * self.criterion(y_right)) / len(y_subset)\n","                if criterion_value < best_criterion_value:\n","                    best_feature = feature_index\n","                    best_threshold = threshold\n","                    best_criterion_value = criterion_value\n","\n","        return best_feature, best_threshold\n","\n","    def calculate_proba(self, y_subset):\n","        if self.classification:\n","            return np.mean(y_subset, axis=0)\n","        return np.mean(y_subset)\n","\n","    def make_tree(self, X_subset, y_subset):\n","        \"\"\"\n","        Recursively builds the tree\n","\n","        Parameters\n","        ----------\n","        X_subset : np.array of type float with shape (n_objects, n_features)\n","            Feature matrix representing the selected subset\n","\n","        y_subset : np.array of type float with shape (n_objects, n_classes) in classification\n","                   (n_objects, 1) in regression\n","            One-hot representation of class labels or target values for corresponding subset\n","\n","        Returns\n","        -------\n","        root_node : Node class instance\n","            Node of the root of the fitted tree\n","        \"\"\"\n","\n","        # YOUR CODE HERE\n","        if y_subset.shape[0] < self.min_samples_split or self.depth >= self.max_depth:\n","            return Node(None, None, proba=self.calculate_proba(y_subset))\n","        feature_index, threshold = self.choose_best_split(X_subset, y_subset)\n","        if feature_index is None:\n","            return Node(None, None, proba=self.calculate_proba(y_subset))\n","\n","        proba = self.calculate_proba(y_subset)\n","        new_node = Node(feature_index, threshold, proba)\n","        self.depth += 1\n","        (X_left, y_left), (X_right, y_right) = self.make_split(feature_index, threshold, X_subset, y_subset)\n","        new_node.left_child = self.make_tree(X_left, y_left)\n","        new_node.right_child = self.make_tree(X_right, y_right)\n","        self.depth -= 1\n","        return new_node\n","\n","    def fit(self, X, y):\n","        \"\"\"\n","        Fit the model from scratch using the provided data\n","\n","        Parameters\n","        ----------\n","        X : np.array of type float with shape (n_objects, n_features)\n","            Feature matrix representing the data to train on\n","\n","        y : np.array of type int with shape (n_objects, 1) in classification\n","                   of type float with shape (n_objects, 1) in regression\n","            Column vector of class labels in classification or target values in regression\n","\n","        \"\"\"\n","        assert len(y.shape) == 2 and len(y) == len(X), 'Wrong y shape'\n","        self.criterion, self.classification = self.all_criterions[self.criterion_name]\n","        if self.classification:\n","            if self.n_classes is None:\n","                self.n_classes = len(np.unique(y))\n","            y = one_hot_encode(self.n_classes, y)\n","\n","        self.root = self.make_tree(X, y)\n","\n","    def traverse(self, node, x):\n","        if node.left_child is None and node.right_child is None:\n","            return node.proba\n","        if x[node.feature_index] < node.value:\n","            return self.traverse(node.left_child, x)\n","        else:\n","            return self.traverse(node.right_child, x)\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Predict the target value or class label  the model from scratch using the provided data\n","\n","        Parameters\n","        ----------\n","        X : np.array of type float with shape (n_objects, n_features)\n","            Feature matrix representing the data the predictions should be provided for\n","\n","        Returns\n","        -------\n","        y_predicted : np.array of type int with shape (n_objects, 1) in classification\n","                   (n_objects, 1) in regression\n","            Column vector of class labels in classification or target values in regression\n","\n","        \"\"\"\n","\n","        # YOUR CODE HERE\n","        y_predicted = np.array([self.traverse(self.root, x) for x in X])\n","        if self.classification:\n","            return one_hot_decode(y_predicted)\n","        return y_predicted\n","\n","    def predict_proba(self, X):\n","        \"\"\"\n","        Only for classification\n","        Predict the class probabilities using the provided data\n","\n","        Parameters\n","        ----------\n","        X : np.array of type float with shape (n_objects, n_features)\n","            Feature matrix representing the data the predictions should be provided for\n","\n","        Returns\n","        -------\n","        y_predicted_probs : np.array of type float with shape (n_objects, n_classes)\n","            Probabilities of each class for the provided objects\n","\n","        \"\"\"\n","        assert self.classification, 'Available only for classification problem'\n","\n","        # YOUR CODE HERE\n","        y_predicted_probs = np.array([self.traverse(self.root, x) for x in X])\n","        return y_predicted_probs\n"]},{"cell_type":"markdown","metadata":{"id":"OezYVR0-TFzH"},"source":["### Test 0: Initialization (0.01 points)"]},{"cell_type":"code","execution_count":84,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"3dee5ee83e0f63188671f08b57d70804","grade":true,"grade_id":"cell-3473b7b6ffd64d07","locked":true,"points":0.01,"schema_version":3,"solution":false,"task":false},"id":"yZJ9RU-vTFzH","executionInfo":{"status":"ok","timestamp":1722351686289,"user_tz":-180,"elapsed":2,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"outputs":[],"source":["# do not change this cell\n","import numpy as np\n","import unittest\n","import sys\n","import io\n","\n","from sklearn.datasets import fetch_california_housing, load_digits\n","from sklearn.metrics import accuracy_score, mean_squared_error\n","from sklearn.model_selection import train_test_split\n","\n","digits_data = load_digits(n_class=2).data\n","digits_target = load_digits(n_class=2).target[:, None]"]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_target, test_size=0.2, random_state=42)"],"metadata":{"id":"w8wJq2rXEelE","executionInfo":{"status":"ok","timestamp":1722351686289,"user_tz":-180,"elapsed":2,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"execution_count":85,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"deS6OOPtTFzI"},"source":["### Test 1: Make splits loops (0.1 points)"]},{"cell_type":"code","execution_count":86,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"48b2963c650791df41dfbd190ed247fd","grade":true,"grade_id":"cell-e3503c286039ec55","locked":true,"points":0.09,"schema_version":3,"solution":false,"task":false},"id":"OoM4No8DTFzJ","executionInfo":{"status":"ok","timestamp":1722351686744,"user_tz":-180,"elapsed":6,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"outputs":[],"source":["X = np.ones((4, 5), dtype=float) * np.arange(4)[:, None]\n","y = np.arange(4)[:, None] + np.asarray([0.2, -0.3, 0.1, 0.4])[:, None]\n","class_estimator = DecisionTree(max_depth=5, criterion_name='gini')\n","\n","(X_l, y_l), (X_r, y_r) = class_estimator.make_split(1, 1., X, y)\n","\n","flag_X = np.array_equal(X[:1], X_l) and np.array_equal(X[1:], X_r)\n","flag_y = np.array_equal(y[:1], y_l) and np.array_equal(y[1:], y_r)\n","assert flag_X and flag_y"]},{"cell_type":"markdown","metadata":{"id":"3DcNOpBXTFzJ"},"source":["### Test 2: Gini accuracy (0.2 points)"]},{"cell_type":"code","execution_count":87,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"4a2a5e274d8d866e1242a339a7751642","grade":true,"grade_id":"cell-e2c4124a6f815118","locked":true,"points":0.2,"schema_version":3,"solution":false,"task":false},"id":"LSYCAKq8TFzK","executionInfo":{"status":"ok","timestamp":1722351687581,"user_tz":-180,"elapsed":380,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"outputs":[],"source":["class_estimator = DecisionTree(max_depth=5, criterion_name='gini')\n","class_estimator.fit(X_train, y_train)\n","ans = class_estimator.predict(X_test)\n","accuracy_gini = accuracy_score(y_test, ans)\n","assert 0.96 < accuracy_gini"]},{"cell_type":"markdown","metadata":{"id":"K7fVBj6pTFzL"},"source":["### Test 3: Entropy accuracy (0.2 points)"]},{"cell_type":"code","execution_count":88,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"b3b167fd8a4950ffe1f1b8f691ab7f91","grade":true,"grade_id":"cell-69473387a23d8dff","locked":true,"points":0.2,"schema_version":3,"solution":false,"task":false},"id":"yZ9AUW7kTFzL","executionInfo":{"status":"ok","timestamp":1722351688334,"user_tz":-180,"elapsed":754,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"outputs":[],"source":["class_estimator = DecisionTree(max_depth=5, criterion_name='entropy')\n","class_estimator.fit(X_train, y_train)\n","ans = class_estimator.predict(X_test)\n","accuracy = accuracy_score(y_test, ans)\n","assert 0.96 < accuracy"]},{"cell_type":"markdown","metadata":{"id":"gmsCuLKWTFzM"},"source":["### Test 4: Entropy probabilities (0.2 points)"]},{"cell_type":"code","execution_count":89,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"2ea5402e3fc351fe4bdc17dc7d48b591","grade":true,"grade_id":"cell-e5f59af66e6c111b","locked":true,"points":0.2,"schema_version":3,"solution":false,"task":false},"id":"UunGM5sATFzM","executionInfo":{"status":"ok","timestamp":1722351690036,"user_tz":-180,"elapsed":1706,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"outputs":[],"source":["class_estimator = DecisionTree(max_depth=10, criterion_name='entropy')\n","class_estimator.fit(X_train, y_train)\n","ans = class_estimator.predict(X_test)\n","reference = np.array([0.48611111, 0.51388889])\n","assert np.abs(np.sum(class_estimator.predict_proba(X_test).mean(axis=0) - reference)) < 1e-6"]},{"cell_type":"markdown","metadata":{"id":"LSSTiOZ4TFzN"},"source":["### Test 5: MSE mad_median (0.15 points)"]},{"cell_type":"code","execution_count":90,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"740411f734d1c9841d5fcc124eb129d1","grade":true,"grade_id":"cell-1a9c1e3609ed9aab","locked":true,"points":0.15,"schema_version":3,"solution":false,"task":false},"id":"nH7WMKffTFzN","executionInfo":{"status":"ok","timestamp":1722351693717,"user_tz":-180,"elapsed":3683,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"outputs":[],"source":["housing = fetch_california_housing()\n","random_indices = np.random.choice(np.arange(len(housing.data)), 500)\n","\n","regr_data = housing.data[random_indices]\n","regr_target = housing.target[random_indices, None]\n","RX_train, RX_test, Ry_train, Ry_test = train_test_split(regr_data, regr_target, test_size=0.2, random_state=42)\n","\n","regressor = DecisionTree(max_depth=8, criterion_name='mad_median')\n","regressor.fit(RX_train, Ry_train)\n","predictions_mad = regressor.predict(RX_test)\n","mse = mean_squared_error(Ry_test, predictions_mad)\n","assert 0.4 < mse < 2"]},{"cell_type":"markdown","metadata":{"id":"Q4WrKnIrTFzO"},"source":["### Test 6: MSE Variance (0.15 points)"]},{"cell_type":"code","execution_count":91,"metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"d8ae6da572b6c3a76405ebfa4b9f4fd6","grade":true,"grade_id":"cell-1ddb0377b6c68deb","locked":true,"points":0.15,"schema_version":3,"solution":false,"task":false},"id":"sRGACAn_TFzO","executionInfo":{"status":"ok","timestamp":1722351695202,"user_tz":-180,"elapsed":1491,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"outputs":[],"source":["housing = fetch_california_housing()\n","random_indices = np.random.choice(np.arange(len(housing.data)), 500)\n","\n","regr_data = housing.data[random_indices]\n","regr_target = housing.target[random_indices, None]\n","RX_train, RX_test, Ry_train, Ry_test = train_test_split(regr_data, regr_target, test_size=0.2, random_state=42)\n","\n","regressor = DecisionTree(max_depth=8, criterion_name='variance')\n","regressor.fit(RX_train, Ry_train)\n","predictions_mad = regressor.predict(RX_test)\n","mse = mean_squared_error(Ry_test, predictions_mad)\n","assert 0.5 < mse < 1.8"]},{"cell_type":"code","source":[],"metadata":{"id":"SEsAPXRGFEB3","executionInfo":{"status":"ok","timestamp":1722351695202,"user_tz":-180,"elapsed":5,"user":{"displayName":"Maxim Trufanov","userId":"13155314945804535834"}}},"execution_count":91,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}