{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "You need to train the model and get score as big as you can\n",
    "\n",
    "Dataset: https://disk.yandex.ru/d/gcGKZ_KsXZN4VA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tqdm.notebook as tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torch_data\n",
    "import torchaudio\n",
    "import urllib\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
    "public_key = 'https://disk.yandex.ru/d/gcGKZ_KsXZN4VA'\n",
    "final_url = base_url + urllib.parse.urlencode(dict(public_key=public_key))\n",
    "response = requests.get(final_url)\n",
    "download_url = response.json()['href']\n",
    "!wget -O data.tar.gz \"{download_url}\"\n",
    "!tar -xf data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu' # also you can use \"cuda\" for gpu and \"mps\" for apple silicon\n",
    "DATADIR = 'ml_trains_data'\n",
    "LOADER_WORKERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch_data.Dataset):\n",
    "    def __init__(self, split_part: str, datadir: str, feats: nn.Module, read_labels=True):\n",
    "        super().__init__()\n",
    "        data = pd.read_csv(os.path.join(datadir, f'{split_part}.tsv'), sep='\\t')\n",
    "        if read_labels:\n",
    "            labels = {key: idx for idx, key in enumerate(sorted(set(data.label.values)))}\n",
    "            self._idx_to_label = {idx: key for idx, key in enumerate(sorted(set(data.label.values)))}\n",
    "        self._classes = len(labels)\n",
    "        self._feats = feats\n",
    "        self._ytids = []\n",
    "        self._pathes = []\n",
    "        self._labels = []\n",
    "        for _, row in data.iterrows():\n",
    "            path = os.path.join(datadir, 'clips', f'{row.YTID}.flac')\n",
    "            if os.path.exists(path):\n",
    "                self._ytids.append(row.YTID)\n",
    "                self._pathes.append(path)\n",
    "                self._labels.append(labels[row.label] if read_labels else 0)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(self._pathes[index])\n",
    "        except Exception as err:\n",
    "            logging.error(\"Can't read file %s\", self._pathes[index])\n",
    "            raise err\n",
    "        assert sample_rate == 16000\n",
    "        assert waveform.shape[0] == 1\n",
    "        feats = self._feats(waveform)[0]\n",
    "        return (feats, self._labels[index])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._pathes)\n",
    "\n",
    "    def classes(self) -> int:\n",
    "        return self._classes\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    max_length = max(item[0].shape[1] for item in batch)\n",
    "    X = torch.zeros((len(batch), batch[0][0].shape[0], max_length))\n",
    "    for idx, item in enumerate(batch):\n",
    "        X[idx, :, :item[0].shape[1]] = item[0]\n",
    "    targets = torch.tensor([item[1] for item in batch], dtype=torch.long).reshape(len(batch), 1)\n",
    "    return (X, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feats part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use LogMelSpectrogram or MFCC to achive better score\n",
    "class LogMelSpectrogram(nn.Module):\n",
    "    pass\n",
    "\n",
    "# FBANK 40 by default, but you can choose something else\n",
    "FEATS = 40\n",
    "transform = torchaudio.transforms.MelSpectrogram(n_mels=FEATS)\n",
    "trainset = Dataset('train', 'data', transform)\n",
    "testset = Dataset('eval', 'data', transform)\n",
    "N_CLASSES = trainset.classes()\n",
    "assert N_CLASSES == 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval part\n",
    "\n",
    "Write balanced accuracy:\n",
    "$$BAcc = \\frac{1}{classes}\\sum_{c = 1}^{classes} \\frac{\\sum_i^n I(y_i = p_i = c)}{\\sum_i^n I(y_i = c)}$$\n",
    "\n",
    "Where:\n",
    "- $y_i$ -- target class for $i$ element\n",
    "- $p_i$ -- predicted class for $i$ element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of pairs (target_class, predicted_class)\n",
    "def balanced_accuracy(items: list[tuple[int, int]], classes=N_CLASSES) -> float:\n",
    "    # <YOUR CODE IS HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(balanced_accuracy([(0, 0), (0, 0), (1, 1)], 2), 1.0)\n",
    "assert np.isclose(balanced_accuracy([(0, 1), (1, 0)], 2), 0.0)\n",
    "assert np.isclose(balanced_accuracy([(0, 0), (0, 0), (1, 0)], 2), 0.5)\n",
    "assert np.isclose(balanced_accuracy([(0, 0), (1, 1), (0, 0), (0, 0), (1, 0), (0, 1)], 2), 0.625)\n",
    "assert np.isclose(balanced_accuracy([(1, 1), (0, 1), (2, 2)], 3), 0.66666666666666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train part\n",
    "Train some model with as big balanced accuracy as you can\n",
    "\n",
    "You can train any model you want. The only limitation is that it must be trained from scratch on the data provided in the task. For example you can choose model from:\n",
    "- DNN\n",
    "- CNN 1d\n",
    "- CNN 2d\n",
    "- Transformer\n",
    "- RNN\n",
    "- mixes of given models\n",
    "\n",
    "Hints:\n",
    "- No need to train large models for this task. 10 million parameters is more than you need.\n",
    "- Watch to overfitting, try to add Augmentation, Dropout, BatchNorm, L1/L2-Regulatization or something else.\n",
    "- Use poolings or strides to reduce time-dimenstion. It is better to reduce the dimension gradually rather than at the end.\n",
    "- Try different features (mel-spec, log-mel-spec, mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage(\n",
    "    model: nn.Module,\n",
    "    data: torch_data.Dataset,\n",
    "    opt: optim.Optimizer,\n",
    "    batch_size: int = 256,\n",
    "    train: bool = True\n",
    "):\n",
    "    loader = torch_data.DataLoader(\n",
    "        data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=LOADER_WORKERS,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    loss_sum, batches = 0.0, 0\n",
    "    pred_pairs = []\n",
    "    for X, Y in tqdm.tqdm(loader):\n",
    "        pred = model.forward(X.to(DEVICE))\n",
    "        loss = F.cross_entropy(pred.squeeze(), Y.squeeze().to(DEVICE))\n",
    "        if train:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        loss_sum += loss.item()\n",
    "        batches += 1\n",
    "        with torch.no_grad():\n",
    "            pred_pairs.extend(zip(\n",
    "                Y.data.numpy().reshape(-1),\n",
    "                torch.argmax(pred, dim=1).cpu().data.numpy().reshape(-1)\n",
    "            ))\n",
    "    return loss_sum / batches, balanced_accuracy(pred_pairs)\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    opt,\n",
    "    batch_size: int = 256,\n",
    "    epochs: int = 10,\n",
    "):\n",
    "    train_data, val_data = torch.utils.data.random_split(trainset, (0.9, 0.1), generator=torch.Generator().manual_seed(42))\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = stage(model, train_data, opt, batch_size=batch_size)\n",
    "        val_loss, val_acc = stage(model, val_data, opt, batch_size=batch_size, train=False)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        clear_output()\n",
    "        fig, axis = plt.subplots(1, 2, figsize=(15, 7))\n",
    "        axis[0].plot(np.arange(1, epoch + 2), train_losses, label='train')\n",
    "        axis[0].plot(np.arange(1, epoch + 2), val_losses, label='val')\n",
    "        axis[1].plot(np.arange(1, epoch + 2), train_accs, label='train')\n",
    "        axis[1].plot(np.arange(1, epoch + 2), val_accs, label='val')\n",
    "        axis[0].set(xlabel='epoch', ylabel='CE Loss')\n",
    "        axis[1].set(xlabel='epoch', ylabel='Accuracy')\n",
    "        fig.legend()\n",
    "        plt.show()\n",
    "        print(f'Epoch {epoch + 1}.')\n",
    "        print(f'Train loss {train_loss}. Train accuracy {train_acc}.')\n",
    "        print(f'Test loss {val_loss}. Test accuracy {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_dim=FEATS, out_dim=N_CLASSES):\n",
    "        super().__init__()\n",
    "        # <YOUR CODE IS HERE>\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        # input: [batch_size, IN_FEATURES, TIME]\n",
    "        # output: [batch_size, N_CLASSES]\n",
    "        # <YOUR CODE IS HERE>\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(DEVICE)\n",
    "opt = optim.Adam(model.parameters())\n",
    "train(model, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction part\n",
    "\n",
    "Prepare result file and send it to Yandex.Contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for idx, ytid in enumerate(testset._ytids):\n",
    "    feats, _ = testset[idx]\n",
    "    predict = torch.argmax(model.forward(feats.reshape(1, FEATS, -1).to(DEVICE)), dim=1).item()\n",
    "    result.append((ytid, trainset._idx_to_label[predict]))\n",
    "pd.DataFrame(result, columns=['YTID', 'label']).to_csv('result.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
